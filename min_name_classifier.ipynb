{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6b238cbd0a47244",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T22:34:13.920111Z",
     "start_time": "2024-03-24T22:34:11.741220Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"conll2003\")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a314408788eb8e79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T22:34:13.961224Z",
     "start_time": "2024-03-24T22:34:13.915300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_feature = raw_datasets[\"train\"].features[\"ner_tags\"]\n",
    "label_names = ner_feature.feature.names\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afed60998a9b05bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T22:34:14.739706Z",
     "start_time": "2024-03-24T22:34:13.928335Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Models to try\n",
    "# distilbert-base-uncased\n",
    "# distilbert-base-cased\n",
    "# distilbert-base-multilingual-cased\n",
    "\n",
    "model_checkpoint = \"distilbert/distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e36605cbf1f169",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b3938cbb47709b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T22:34:14.749552Z",
     "start_time": "2024-03-24T22:34:14.741630Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b62371674891fa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T22:34:15.350996Z",
     "start_time": "2024-03-24T22:34:15.335450Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61366c9d10466df9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T22:34:16.029039Z",
     "start_time": "2024-03-24T22:34:16.007908Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "458ecdb36fe24198",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T22:34:19.348806Z",
     "start_time": "2024-03-24T22:34:19.071260Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a016d68fd17a709b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T22:34:21.504498Z",
     "start_time": "2024-03-24T22:34:20.613726Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fa8928b44a40e6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ace458cf0f575fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T22:34:22.788663Z",
     "start_time": "2024-03-24T22:34:22.780186Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ca7b9323c64f975",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T22:34:23.824352Z",
     "start_time": "2024-03-24T22:34:23.701957Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9d693ff40a02bee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T22:34:25.757109Z",
     "start_time": "2024-03-24T22:34:25.745881Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bd15341ab09c25a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T22:34:28.698123Z",
     "start_time": "2024-03-24T22:34:28.692897Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "# \n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0289aab8ab0c5c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T22:34:35.031206Z",
     "start_time": "2024-03-24T22:34:35.000712Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "output_dir = \"models/distilbert-uncased-finetuned-ner\"\n",
    "args = TrainingArguments(\n",
    "    output_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aeebad4877d57d90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T22:34:36.328848Z",
     "start_time": "2024-03-24T22:34:36.188179Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackfriedson/.pyenv/versions/3.10.13/envs/min_name_classifier/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bd18634c0bc16b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T22:34:40.585597Z",
     "start_time": "2024-03-24T22:34:40.571487Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trainer.push_to_hub(commit_message=\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd910ef980e52095",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T22:34:43.416040Z",
     "start_time": "2024-03-24T22:34:43.314139Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trained_model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"jackfriedson/distilbert-uncased-finetuned-ner\",\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81c6b2c05610bb0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "383e1f827b152281",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T00:03:43.863244Z",
     "start_time": "2024-03-25T00:03:43.845857Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"], collate_fn=data_collator, batch_size=8\n",
    ")\n",
    "\n",
    "def postprocess(predictions, labels):\n",
    "    predictions = predictions.detach().cpu().clone().numpy()\n",
    "    labels = labels.detach().cpu().clone().numpy()\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    return true_predictions, true_labels\n",
    "\n",
    "\n",
    "def evaluate_model(model, eval_dataloader, metric) -> dict:\n",
    "    model.eval()\n",
    "    for batch in tqdm(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "    \n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        labels = batch[\"labels\"]\n",
    "    \n",
    "        true_predictions, true_labels = postprocess(predictions, labels)\n",
    "        metric.add_batch(predictions=true_predictions, references=true_labels)\n",
    "        \n",
    "    return metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6413d961b76482b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T22:35:07.979932Z",
     "start_time": "2024-03-24T22:34:45.733617Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654297bd75624013bff610059721d4b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.965160587915079,\n",
       "  'recall': 0.9511802575107297,\n",
       "  'f1': 0.9581194271818428,\n",
       "  'number': 1864},\n",
       " 'MISC': {'precision': 0.8633405639913232,\n",
       "  'recall': 0.8522483940042827,\n",
       "  'f1': 0.8577586206896551,\n",
       "  'number': 934},\n",
       " 'ORG': {'precision': 0.9060402684563759,\n",
       "  'recall': 0.8823529411764706,\n",
       "  'f1': 0.8940397350993378,\n",
       "  'number': 1377},\n",
       " 'PER': {'precision': 0.9782844733984799,\n",
       "  'recall': 0.9740540540540541,\n",
       "  'f1': 0.9761646803900326,\n",
       "  'number': 1850},\n",
       " 'overall_precision': 0.9400875126220128,\n",
       " 'overall_recall': 0.9271369294605809,\n",
       " 'overall_f1': 0.9335673101027826,\n",
       " 'overall_accuracy': 0.9852256660365069}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(trained_model, eval_dataloader, metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bed43461f87665",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48ab7c256a5b3b16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T22:35:59.584158Z",
     "start_time": "2024-03-24T22:35:59.576697Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "word_split_regex = re.compile(r'\\w+|[.,!?;]')\n",
    "\n",
    "def split_into_words(input: str) -> list[str]:\n",
    "    return word_split_regex.findall(input)\n",
    "\n",
    "def label_ids_to_names(label_ids: list[int]) -> list[str]:\n",
    "    return [label_names[label_id] for label_id in label_ids if label_id != -100]\n",
    "\n",
    "def align_predictions_with_words(predictions: list[int] | torch.Tensor, word_ids: list[int | None]) -> list[int]:\n",
    "    if len(predictions) != len(word_ids):\n",
    "        raise ValueError(f\"Predictions and word_ids should have the same length, got {len(predictions)} predictions and {len(word_ids)} word_ids\")\n",
    "\n",
    "    word_predictions = []\n",
    "    current_word = None\n",
    "    for prediction, word_id in zip(predictions, word_ids):\n",
    "        if word_id is None:\n",
    "            continue\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word\n",
    "            word_predictions.append(prediction)\n",
    "        current_word = word_id\n",
    "    return word_predictions\n",
    "\n",
    "\n",
    "class NER:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def get_predictions(self, input: list[str]) -> list[str]:\n",
    "        # Input must already be split into words\n",
    "        tokenized_inputs = self.tokenizer(input, return_tensors=\"pt\", is_split_into_words=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**tokenized_inputs)\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        word_predictions = align_predictions_with_words(predictions.tolist()[0], tokenized_inputs.word_ids())\n",
    "        return label_ids_to_names(word_predictions)\n",
    "    \n",
    "    def get_predictions_batch(self, inputs: list[list[str]]) -> list[list[str]]:\n",
    "        # Inputs must already be split into words\n",
    "        tokenized_inputs = self.tokenizer(inputs, return_tensors=\"pt\", padding=True, truncation=True, is_split_into_words=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**tokenized_inputs)\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        word_predictions = []\n",
    "        for i in range(len(inputs)):\n",
    "            word_prediction = align_predictions_with_words(predictions[i], tokenized_inputs.word_ids(batch_index=i))\n",
    "            word_predictions.append(label_ids_to_names(word_prediction))\n",
    "        return word_predictions\n",
    "    \n",
    "    def time_inference(self, word_inputs: list[list[str]]) -> None:\n",
    "        result = %timeit -r 15 -o self.get_predictions_batch(word_inputs)\n",
    "        print(f\"Predicted {len(word_inputs)} words in {1000 * result.average:.2f} ms\")\n",
    "        print(f\"{1000 * result.average / len(word_inputs):.2f} ms per word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "637e050af201db4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T22:36:00.479758Z",
     "start_time": "2024-03-24T22:36:00.464557Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ner = NER(trained_model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "284355df55486811",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T22:36:01.186499Z",
     "start_time": "2024-03-24T22:36:01.157343Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-PER', 'I-PER']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner.get_predictions(split_into_words(\"john smith\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f00a604762c1fef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T22:36:01.951272Z",
     "start_time": "2024-03-24T22:36:01.922226Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner.get_predictions(split_into_words(\"building\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "455e3e5cf4493b6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T22:36:02.598410Z",
     "start_time": "2024-03-24T22:36:02.549620Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['B-PER', 'I-PER'],\n",
       " ['B-PER', 'I-PER'],\n",
       " ['O'],\n",
       " ['B-ORG'],\n",
       " ['B-PER', 'O', 'B-PER'],\n",
       " ['B-PER', 'O', 'O', 'O', 'O', 'O', 'B-PER']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_inputs = [\"john smith\", \"abraham lincoln\", \"building\", \"datadog\", \"smith, john\", \"sylvain went to the store with martha\"]\n",
    "inputs = list(map(split_into_words, raw_inputs))\n",
    "ner.get_predictions_batch(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12df2ce197e2a51e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T22:36:08.039682Z",
     "start_time": "2024-03-24T22:36:03.451283Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.4 ms ± 3.17 ms per loop (mean ± std. dev. of 15 runs, 10 loops each)\n",
      "Predicted 6 words in 28.41 ms\n",
      "4.73 ms per word\n"
     ]
    }
   ],
   "source": [
    "ner.time_inference(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8332eba2b7203e85",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T17:25:47.782535Z",
     "start_time": "2024-03-25T17:25:29.304146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 ms ± 6.69 ms per loop (mean ± std. dev. of 15 runs, 10 loops each)\n",
      "Predicted 60 words in 114.66 ms\n",
      "1.91 ms per word\n"
     ]
    }
   ],
   "source": [
    "inputs_med = list(map(split_into_words, raw_inputs * 10))\n",
    "ner.time_inference(inputs_med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bc0bf7b7fb0c1bcd",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T17:26:01.488950Z",
     "start_time": "2024-03-25T17:25:47.786570Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857 ms ± 58.7 ms per loop (mean ± std. dev. of 15 runs, 1 loop each)\n",
      "Predicted 600 words in 856.61 ms\n",
      "1.43 ms per word\n"
     ]
    }
   ],
   "source": [
    "inputs_large = list(map(split_into_words, raw_inputs * 100))\n",
    "ner.time_inference(inputs_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa89d285c9be354",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Eval on names dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e4adcc3ccb6360dd",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T17:25:01.154070Z",
     "start_time": "2024-03-25T17:24:54.044758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d7d062784b440f6b1c8e59609a2121b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/131491 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "44f840132486430dbd3b0bcaa2246dc1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/14611 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c19219239b74437aa0ee51d7ce3512c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "names_datasets = load_dataset(\"csv\", data_files=\"data/names_dataset.csv\", split=\"train[:20%]\").train_test_split(test_size=0.1, shuffle=False)\n",
    "def parse_lists(example):\n",
    "    example[\"tokens\"] = ast.literal_eval(example[\"tokens\"])\n",
    "    example[\"ner_tags\"] = ast.literal_eval(example[\"ner_tags\"])\n",
    "    return example\n",
    "\n",
    "names_datasets = names_datasets.map(parse_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "26e65130413e8308",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T17:25:02.203655Z",
     "start_time": "2024-03-25T17:25:02.178403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'ner_tags', 'is_name', 'name_type'],\n        num_rows: 131491\n    })\n    test: Dataset({\n        features: ['id', 'tokens', 'ner_tags', 'is_name', 'name_type'],\n        num_rows: 14611\n    })\n})"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "48f4025b673c3e6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T00:11:58.838566Z",
     "start_time": "2024-03-25T00:11:57.104706Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18723bd3b3384ccd916b885d93178213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/131491 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e1f99578fe4a36b581db6285b81f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14611 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_names_datasets = names_datasets.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=names_datasets[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "45632194a4fc49c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T00:15:02.081045Z",
     "start_time": "2024-03-25T00:15:02.070434Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "batch_size = 64\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_names_datasets[\"test\"], collate_fn=data_collator, batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "17104505a58f00e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T00:12:58.239188Z",
     "start_time": "2024-03-25T00:12:01.921649Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d41229ace4248338445244b04777268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1827 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackfriedson/.pyenv/versions/3.10.13/envs/min_name_classifier/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 0},\n",
       " 'MISC': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 0},\n",
       " 'ORG': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 0},\n",
       " 'PER': {'precision': 0.7306962025316456,\n",
       "  'recall': 0.3418714835652946,\n",
       "  'f1': 0.46580593100665724,\n",
       "  'number': 6754},\n",
       " 'overall_precision': 0.20313187296560217,\n",
       " 'overall_recall': 0.3418714835652946,\n",
       " 'overall_f1': 0.25484244798852157,\n",
       " 'overall_accuracy': 0.5106166091916629}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(trained_model, eval_dataloader, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fcf24d4eb375fb85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T22:43:44.382546Z",
     "start_time": "2024-03-24T22:43:44.372387Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# i = 9\n",
    "# example = list(DataLoader(tokenized_names_datasets[\"test\"], collate_fn=data_collator, batch_size=1))[i]\n",
    "# \n",
    "# with torch.no_grad():\n",
    "#     outputs = trained_model(**example)\n",
    "# \n",
    "# predictions = outputs.logits.argmax(dim=-1)\n",
    "# labels = example[\"labels\"]\n",
    "# \n",
    "# true_predictions, true_labels = postprocess(predictions, labels)\n",
    "# print(names_datasets[\"test\"][i][\"tokens\"])\n",
    "# print(true_predictions)\n",
    "# print(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8847daf29d66685b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T00:15:10.976182Z",
     "start_time": "2024-03-25T00:15:07.936310Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackfriedson/.pyenv/versions/3.10.13/envs/min_name_classifier/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
      "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/Users/jackfriedson/dev/min_name_classifier/models/distilbert-uncased-names-accelerate is already a clone of https://huggingface.co/jackfriedson/distilbert-uncased-names-accelerate. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "from huggingface_hub import Repository, get_full_repo_name\n",
    "from torch.optim import AdamW\n",
    "from transformers import Trainer, TrainingArguments, get_scheduler\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_names_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")\n",
    "\n",
    "num_train_epochs = 2\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "\n",
    "model_name = \"distilbert-uncased-names-accelerate\"\n",
    "output_dir = f\"models/{model_name}\"\n",
    "repo_name = get_full_repo_name(model_name)\n",
    "repo = Repository(output_dir, clone_from=repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e5574206f804954f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T17:26:31.894227Z",
     "start_time": "2024-03-25T17:26:31.885436Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "# from tqdm.auto import tqdm\n",
    "# import torch\n",
    "# \n",
    "# for epoch in range(num_train_epochs):\n",
    "#     # Training\n",
    "#     model.train()\n",
    "#     for batch in tqdm(train_dataloader):\n",
    "#         outputs = model(**batch)\n",
    "#         loss = outputs.loss\n",
    "#         accelerator.backward(loss)\n",
    "# \n",
    "#         optimizer.step()\n",
    "#         lr_scheduler.step()\n",
    "#         optimizer.zero_grad()\n",
    "# \n",
    "#     # Evaluation\n",
    "#     model.eval()\n",
    "#     for batch in tqdm(eval_dataloader):\n",
    "#         with torch.no_grad():\n",
    "#             outputs = model(**batch)\n",
    "# \n",
    "#         predictions = outputs.logits.argmax(dim=-1)\n",
    "#         labels = batch[\"labels\"]\n",
    "# \n",
    "#         # Necessary to pad predictions and labels for being gathered\n",
    "#         predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n",
    "#         labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
    "# \n",
    "#         predictions_gathered = accelerator.gather(predictions)\n",
    "#         labels_gathered = accelerator.gather(labels)\n",
    "# \n",
    "#         true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n",
    "#         metric.add_batch(predictions=true_predictions, references=true_labels)\n",
    "# \n",
    "#     results = metric.compute()\n",
    "#     print(\n",
    "#         f\"epoch {epoch}:\",\n",
    "#         {\n",
    "#             key: results[f\"overall_{key}\"]\n",
    "#             for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]\n",
    "#         },\n",
    "#     )\n",
    "# \n",
    "#     # Save and upload\n",
    "#     accelerator.wait_for_everyone()\n",
    "#     unwrapped_model = accelerator.unwrap_model(model)\n",
    "#     unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "#     if accelerator.is_main_process:\n",
    "#         tokenizer.save_pretrained(output_dir)\n",
    "#         repo.push_to_hub(\n",
    "#             commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "60e8827ade92cb79",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T00:27:35.702757Z",
     "start_time": "2024-03-25T00:27:31.388291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/916 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "46ff54f774f346fcbc7bd3e1ad948395"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dc948ccfa5ee40b3a3a0a8ab738d56f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trained_names_model = AutoModelForTokenClassification.from_pretrained(\n",
    "    repo_name,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/229 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9cfa6433a1a64dc1bd50d44acd1bed7f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'PER': {'precision': 0.8917657045840407,\n  'recall': 0.9332247557003257,\n  'f1': 0.9120243090724931,\n  'number': 6754},\n 'overall_precision': 0.8917657045840407,\n 'overall_recall': 0.9332247557003257,\n 'overall_f1': 0.9120243090724931,\n 'overall_accuracy': 0.9430672132214197}"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataloader = DataLoader(\n",
    "    tokenized_names_datasets[\"test\"], collate_fn=data_collator, batch_size=batch_size\n",
    ")\n",
    "evaluate_model(trained_names_model, eval_dataloader, metric)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T00:30:42.541239Z",
     "start_time": "2024-03-25T00:30:19.910745Z"
    }
   },
   "id": "85470568c3a935b3",
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T17:05:04.248407Z",
     "start_time": "2024-03-25T17:05:04.241136Z"
    }
   },
   "id": "42bae908a8b111d4",
   "execution_count": 95
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
